# Построение эффективных AI-агентов

За последний год специалисты Anthropic работали с десятками команд, создающих агентов на основе больших языковых моделей (LLM) в различных отраслях. Последовательно отмечалось, что наиболее успешные реализации не использовали сложные фреймворки или специализированные библиотеки. Вместо этого они строились на простых, компонуемых паттернах.

## Что такое агенты?

Термин "агент" можно определить по-разному. Некоторые клиенты определяют агентов как полностью автономные системы, которые работают независимо в течение длительного времени, используя различные инструменты для выполнения сложных задач. Другие используют этот термин для описания более регламентированных реализаций, следующих предопределенным рабочим процессам. В Anthropic все эти вариации классифицируются как **агентные системы**, но проводится важное архитектурное различие между **рабочими процессами (workflows)** и **агентами (agents)**:

- **Рабочие процессы** — это системы, где LLM и инструменты оркестрируются через предопределенные пути в коде.
- **Агенты** — это системы, где LLM динамически направляют собственные процессы и использование инструментов, сохраняя контроль над способом выполнения задач[^1].


## Когда (и когда не) использовать агентов

При создании приложений с LLM рекомендуется находить максимально простое решение и усложнять его только при необходимости. Это может означать полный отказ от агентных систем. Агентные системы часто обменивают задержку и стоимость на повышение производительности задач, и следует учитывать, когда такой компромисс имеет смысл[^1].

Когда требуется большая сложность:

- Рабочие процессы обеспечивают предсказуемость и согласованность для четко определенных задач
- Агенты являются лучшим выбором, когда требуется гибкость и принятие решений на основе модели

Однако для многих приложений достаточно оптимизации отдельных вызовов LLM с использованием поиска и примеров в контексте[^1].

## Когда и как использовать фреймворки

Существует множество фреймворков, упрощающих реализацию агентных систем, включая:

- LangGraph от LangChain
- Amazon Bedrock's AI Agent framework
- Rivet (графический интерфейс для создания рабочих процессов LLM)
- Vellum (инструмент для создания и тестирования сложных рабочих процессов)[^1]

Эти фреймворки упрощают начало работы, но часто создают дополнительные уровни абстракции, затрудняющие отладку. Разработчикам рекомендуется начинать с прямого использования API LLM, так как многие паттерны можно реализовать всего несколькими строками кода[^1].

## Строительные блоки, рабочие процессы и агенты

### Строительный блок: Дополненная LLM

Базовым строительным блоком агентных систем является LLM, усиленная такими возможностями, как поиск, инструменты и память. Современные модели могут активно использовать эти возможности — генерировать собственные поисковые запросы, выбирать подходящие инструменты и определять, какую информацию сохранять[^1].

### Рабочий процесс: Цепочка промптов

Цепочка промптов разбивает задачу на последовательность шагов, где каждый вызов LLM обрабатывает вывод предыдущего.

**Пример использования цепочки промптов:**

- Генерация маркетингового текста, а затем его перевод на другой язык
- Создание плана документа, проверка соответствия плана определенным критериям, затем написание документа на основе плана
- В российском контексте: разработка технического задания для IT-проекта, проверка его соответствия ГОСТ, а затем генерация кода на основе ТЗ[^1]


### Рабочий процесс: Маршрутизация

Маршрутизация классифицирует входные данные и направляет их к специализированной последующей задаче.

**Пример использования маршрутизации:**

- Направление различных типов запросов в службу поддержки (общие вопросы, запросы на возврат, техническая поддержка) в различные нисходящие процессы
- Маршрутизация простых вопросов к меньшим моделям, а сложных вопросов к более мощным моделям для оптимизации затрат и скорости
- В российском контексте: распределение обращений клиентов телекоммуникационной компании между специалистами разного профиля[^1]


### Рабочий процесс: Параллелизация

LLM могут иногда работать над задачей одновременно, а их выводы объединяются программно. Этот рабочий процесс проявляется в двух ключевых вариациях:

- **Секционирование**: Разбиение задачи на независимые подзадачи, выполняемые параллельно
- **Голосование**: Выполнение одной и той же задачи несколько раз для получения разнообразных выводов[^1]

**Примеры использования параллелизации:**

**Секционирование**:

- Реализация ограничений, когда один экземпляр модели обрабатывает запросы пользователей, а другой проверяет их на наличие неприемлемого содержания
- В российском контексте: параллельная проверка юридического документа на соответствие нескольким аспектам законодательства РФ

**Голосование**:

- Проверка кода на уязвимости, когда несколько разных промптов оценивают и помечают код при обнаружении проблемы
- Оценка неприемлемости контента с различными порогами голосования[^1]


### Рабочий процесс: Оркестратор-исполнители

В рабочем процессе оркестратор-исполнители центральная LLM динамически разбивает задачи, делегирует их рабочим LLM и синтезирует их результаты.

**Примеры использования оркестратора-исполнителей:**

- Продукты для программирования, которые вносят сложные изменения в несколько файлов
- Задачи поиска, включающие сбор и анализ информации из нескольких источников
- В российском контексте: анализ большого массива данных государственных закупок с распределением подзадач между отдельными исполнителями[^1]


### Рабочий процесс: Оценщик-оптимизатор

В рабочем процессе оценщик-оптимизатор один вызов LLM генерирует ответ, а другой предоставляет оценку и обратную связь в цикле.

**Примеры использования оценщика-оптимизатора:**

- Литературный перевод, где есть нюансы, которые LLM-переводчик может не уловить сразу
- Сложные поисковые задачи, требующие нескольких раундов поиска и анализа
- В российском контексте: итеративное улучшение текста технической документации с учетом отраслевых стандартов и требований[^1]


### Агенты

Агенты появляются в производстве по мере того, как LLM совершенствуются в ключевых возможностях — понимании сложных входных данных, рассуждении и планировании, надежном использовании инструментов и восстановлении после ошибок[^1].

Агенты могут обрабатывать сложные задачи, но их реализация часто проста. Они обычно представляют собой LLM, использующие инструменты на основе обратной связи из окружающей среды в цикле[^1].

**Примеры использования агентов:**

- Агент для программирования для решения задач SWE-bench, которые включают редактирование многих файлов на основе описания задачи
- Реализация "использования компьютера", где модель использует компьютер для выполнения задач
- В российском контексте: автоматизированный помощник, обрабатывающий запросы на государственные услуги, взаимодействуя с различными государственными информационными системами[^1]


## Резюме

Успех в области LLM заключается не в создании самой сложной системы, а в создании *правильной* системы для ваших потребностей. Начните с простых промптов, оптимизируйте их с помощью комплексной оценки и добавляйте многоэтапные агентные системы только тогда, когда более простые решения не справляются[^1].

При реализации агентов рекомендуется следовать трем основным принципам:

- Поддерживать **простоту** в дизайне агента
- Приоритет **прозрачности**, явно показывая этапы планирования агента
- Тщательно разрабатывать интерфейс агент-компьютер через **документацию и тестирование** инструментов[^1]


## Приложение 1: Агенты на практике

Работа с клиентами выявила два особенно перспективных применения AI-агентов:

### A. Поддержка клиентов

Поддержка клиентов сочетает привычные интерфейсы чат-ботов с расширенными возможностями через интеграцию инструментов. Это естественно подходит для более открытых агентов, потому что:

- Взаимодействия поддержки естественно следуют потоку разговора
- Инструменты могут быть интегрированы для получения данных о клиентах, истории заказов и статей базы знаний
- Действия, такие как выдача возмещений или обновление заявок, могут обрабатываться программно
- Успех можно четко измерить через разрешения, определенные пользователем[^1]

**Пример из российской практики:** Банк "Тинькофф" использует интеллектуальных агентов для обработки стандартных запросов клиентов, используя доступ к внутренним системам для проверки баланса, истории операций и выполнения простых действий.

### B. Агенты для программирования

Пространство разработки программного обеспечения показало замечательный потенциал для функций LLM. Агенты особенно эффективны, потому что:

- Решения кода можно проверить через автоматизированные тесты
- Агенты могут итерировать решения, используя результаты тестов в качестве обратной связи
- Пространство проблем хорошо определено и структурировано
- Качество вывода можно объективно измерить[^1]

**Пример из российской практики:** Компания "Яндекс" экспериментирует с агентами для автоматизации отладки программного обеспечения, где агент анализирует логи, определяет причины сбоев и предлагает исправления.

## Приложение 2: Разработка промптов для ваших инструментов

Независимо от того, какую агентную систему вы создаете, инструменты, вероятно, будут важной частью вашего агента. Инструменты позволяют LLM взаимодействовать с внешними сервисами и API. Определения и спецификации инструментов должны получать такое же внимание к инженерии промптов, как и ваши общие промпты[^1].

Рекомендации по форматам инструментов:

- Дайте модели достаточно токенов для "размышлений"
- Сохраняйте формат близким к тому, что модель видела в тексте в интернете
- Убедитесь, что нет "накладных расходов" форматирования[^1]

Одно эмпирическое правило — думать о том, сколько усилий вкладывается в интерфейсы человек-компьютер (HCI), и планировать вложить столько же усилий в создание хороших интерфейсов *агент*-компьютер (ACI)[^1].

**Практический пример из российской разработки:** При создании агента для анализа юридических документов разработчики "Консультант Плюс" обнаружили, что модель делала ошибки при ссылках на статьи законов. Они изменили инструмент, чтобы всегда требовать полную ссылку на закон с датой и номером, что привело к безошибочному использованию этого метода моделью.

[^1]: https://www.anthropic.com/engineering/building-effective-agents

[^2]: https://www.anthropic.com/engineering/building-effective-agents